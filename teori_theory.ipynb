{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b52356",
   "metadata": {},
   "source": [
    "# Teori\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de94a33",
   "metadata": {},
   "source": [
    "Studerande ska kunna:<br>\n",
    "• peka ut ingest —> storage —> transform —> access (teori) <br>\n",
    "• känna igen teknologityper (Psycopg3, Pandas) (teori) Bonus: pydantic <br>\n",
    "• förklara Extract —> Transform —> Load (teori) <br>\n",
    "• Få ut information från en produkt. (Average mm.. mest sold osv..) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0170029a",
   "metadata": {},
   "source": [
    "### 1. ingest —> storage —> transform —> access "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20dc002",
   "metadata": {},
   "source": [
    "Ingest: <br>\n",
    "- First importerar vi Pandas as pd (alias), \n",
    "- skapar vi en variabel \"df\" som står för \"DataFrame. Det är här att alla data ska lagras i ett tabellformat (rader och kolumner).\n",
    "- Från modulen \"pd (Pandas) anropar vi funktionen \".read_csv\" för att läsa filen \"lab1_data.csv\" \n",
    "- och med sep=\";\" för att tala om att datan är separerad med semikolon\n",
    "- Slutligen med print(df) skriver vi ut tabellen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6926ee4",
   "metadata": {},
   "source": [
    "Storage: <br>\n",
    "- I labbet använder vi CSV files\n",
    "- Tidigare har vi använt PostgreSQL och DuckDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da3c5c6",
   "metadata": {},
   "source": [
    "Transform: <br>\n",
    "- Transform lagret är mellansteget i ETL: Extract, Transform, Load där vi \"tvättar\" raw datan och förbereder den innan vi börjar analysera\n",
    "- Det innebär att:\n",
    "    - vi hanterar tomma värden (missing data), \n",
    "    - vi konverterar datatyper (från string till float i labbet), datum med till exempel pd.to_datetime,\n",
    "    - vi tog bort onödiga mellanslag med .strip() osv..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05f705a",
   "metadata": {},
   "source": [
    "Access: <br>\n",
    "- Det är den destinationen i datapipeline efter Ingest och Transform.\n",
    "- I det här labbet är det resultat med de (output) CSV filer\n",
    "- I mitt tidigare jobb var det PowerBI som jag använde för att skapa dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2805d61",
   "metadata": {},
   "source": [
    "### 2. Att känna igen teknologityper (Psycopg3, Pandas) (teori) Bonus: pydantic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f460f44b",
   "metadata": {},
   "source": [
    "Pryscopg3: <br>\n",
    "- Det är en adapter (driver) mellan Python och databasen PostgreSQL\n",
    "- Det fungerar som ett \"rör\" som transporterar data och SQL-frågor mellan koden och databasen\n",
    "- Connection Pool: Psycopg3 har inbyggt stöd för en pool. Istället för att öppna/stänga en ny anslutning för varje fråga håller poolen en uppsättning \"redo\" anslutningar öppna. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7512351e",
   "metadata": {},
   "source": [
    "Pandas: <br>\n",
    "- Pandas är ett bibliotek för datamanipulering och analys\n",
    "- I labbet använde vi Pandas med objektet DataFrame \"df\" som är en virtuell tabell i datorens minne\n",
    "- Pandas används för att transformera, tvätta och räkna datan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb22154",
   "metadata": {},
   "source": [
    "Pydantic: <br>\n",
    "- Pydantic är ett biblioktek för datavalidering och parsing\n",
    "- Är en schema som använder typannoteringar för att hjälpa att inkommande data (kan vara från API eller CSV fil) följer reglerna av scheman\n",
    "- Med parsing betyder det att Pydantic byter till rätt datatyp, till exempel gör att en sträng \"789\" blir integer 789 (om schema vill det så). När det inte går att parsa eller om datan är fel kastas ett fel medellandet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8527c21c",
   "metadata": {},
   "source": [
    "### 3. Förklara Extract —> Transform —> Load (teori)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e89f6e0",
   "metadata": {},
   "source": [
    "Nedan är förklaring av Extract Transform Load pipeline (ELT)\n",
    "\n",
    "Extract: <br>\n",
    "- Procesen som hämtar raw datan från källan som till exempel CSV filen från labbet eller via Pysocopg3 från en databas\n",
    "- Med Pandas med .read_csv kan vi läsa in datan i minnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af5a6e1",
   "metadata": {},
   "source": [
    "Transform: <br>\n",
    "- Det handlar om tvätta och strukturera datan. \n",
    "- I labbet inom en Pandas DataFrame använder vi metoder för att tvätta datan såsom:\n",
    "    - .isna() för att identifiera tomma celler eller Not a Number (NaN)\n",
    "    - .strip() för att ta bort spaces/mellanrum före och efter värdet\n",
    "    - .replace() för att byta ut specifika värden mot nya\n",
    "    - pd.to_datetime() som omvandlar textsträngar, till ex: 2024/02/15 ---> 2024-02-15\n",
    "    - astype() som tvingar en kolumn till en specifik datatyp, till exempel från integer till float\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d554b5",
   "metadata": {},
   "source": [
    "Load: <br>\n",
    "- Det här steget när färdiga datan skickas till destinationen som vi såg tidigare med Access (lite högre)\n",
    "- Datan är redo för \"slutanvändaren\" i BI vertyg som PowerBI till exempel.\n",
    "- Ideen är att datan sak från minne till en fysik fil eller databas\n",
    "- I labbet anänder vi .to_csv() för att skapa filen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DE25_Labb1_Programmering_Data_platform_Christophe_Giraud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
